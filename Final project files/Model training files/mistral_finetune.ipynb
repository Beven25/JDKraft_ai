{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147f7f43",
   "metadata": {
    "papermill": {
     "duration": 0.007491,
     "end_time": "2024-01-17T21:06:48.501235",
     "exception": false,
     "start_time": "2024-01-17T21:06:48.493744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Mistral 7B Finetuning using Qlora"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f973e96",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.006294,
     "end_time": "2024-01-17T21:06:48.514217",
     "exception": false,
     "start_time": "2024-01-17T21:06:48.507923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd451a7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:06:48.528167Z",
     "iopub.status.busy": "2024-01-17T21:06:48.527845Z",
     "iopub.status.idle": "2024-01-17T21:07:06.854916Z",
     "shell.execute_reply": "2024-01-17T21:07:06.853875Z"
    },
    "papermill": {
     "duration": 18.336306,
     "end_time": "2024-01-17T21:07:06.856866",
     "exception": false,
     "start_time": "2024-01-17T21:06:48.520560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.39.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "!pip install wandb\n",
    "import wandb\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_hf = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "secret_wandb = user_secrets.get_secret(\"wandb\")\n",
    "!huggingface-cli login --token $secret_hf\n",
    "wandb_api = user_secrets.get_secret(\"wandb\") \n",
    "wandb.login(key=wandb_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9feb1c67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:07:06.873651Z",
     "iopub.status.busy": "2024-01-17T21:07:06.873295Z",
     "iopub.status.idle": "2024-01-17T21:09:05.069281Z",
     "shell.execute_reply": "2024-01-17T21:09:05.067838Z"
    },
    "papermill": {
     "duration": 118.207317,
     "end_time": "2024-01-17T21:09:05.071987",
     "exception": false,
     "start_time": "2024-01-17T21:07:06.864670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808da9e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:09:05.089928Z",
     "iopub.status.busy": "2024-01-17T21:09:05.089558Z",
     "iopub.status.idle": "2024-01-17T21:09:06.770746Z",
     "shell.execute_reply": "2024-01-17T21:09:06.769765Z"
    },
    "papermill": {
     "duration": 1.692901,
     "end_time": "2024-01-17T21:09:06.773233",
     "exception": false,
     "start_time": "2024-01-17T21:09:05.080332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb61508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:09:06.789504Z",
     "iopub.status.busy": "2024-01-17T21:09:06.789024Z",
     "iopub.status.idle": "2024-01-17T21:09:24.295520Z",
     "shell.execute_reply": "2024-01-17T21:09:24.294752Z"
    },
    "papermill": {
     "duration": 17.517117,
     "end_time": "2024-01-17T21:09:24.297859",
     "exception": false,
     "start_time": "2024-01-17T21:09:06.780742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM, prepare_model_for_kbit_training, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a68cfbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:09:24.314807Z",
     "iopub.status.busy": "2024-01-17T21:09:24.314224Z",
     "iopub.status.idle": "2024-01-17T21:09:26.132991Z",
     "shell.execute_reply": "2024-01-17T21:09:26.132071Z"
    },
    "papermill": {
     "duration": 1.829304,
     "end_time": "2024-01-17T21:09:26.134956",
     "exception": false,
     "start_time": "2024-01-17T21:09:24.305652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/BevenRozario--job_desc_5k to /root/.cache/huggingface/datasets/parquet/BevenRozario--job_desc_5k-3d63b85cb90728c8/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00643eceb8324e93b1f4943e4544251a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce53e6eba91459c98d657d304575abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56daaaa054b94ef28410787b069f967d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/233k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e0a7fe2a204ca7a6ecbf95095ef1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/BevenRozario--job_desc_5k-3d63b85cb90728c8/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df710e071eb64015bfd73d08a876432d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"BevenRozario/job_desc_5k\")\n",
    "\n",
    "# Accessing the train and validation datasets\n",
    "train_dataset = dataset['train_dataset']\n",
    "eval_dataset = dataset['eval_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1493f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:09:26.153524Z",
     "iopub.status.busy": "2024-01-17T21:09:26.153015Z",
     "iopub.status.idle": "2024-01-17T21:09:26.159247Z",
     "shell.execute_reply": "2024-01-17T21:09:26.158359Z"
    },
    "papermill": {
     "duration": 0.017374,
     "end_time": "2024-01-17T21:09:26.161159",
     "exception": false,
     "start_time": "2024-01-17T21:09:26.143785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Instruction': 'Generate a job description for a Social Media Manager role.The candidate should have skills in Social media analytics tools example Google Analytics, Facebook Insights Data analysis and reporting Social media ROI measurement Competitive analysis Trend identification. The job description should include the sector (Biotechnology) and industry (Pharmaceuticals) of the company.',\n",
       " 'Response': 'Job Description: Social Media Manager (Pharmaceuticals - Biotechnology)\\n\\nWe are currently seeking a skilled and experienced Social Media Manager to join our team in the Pharmaceuticals industry, specializing in the Biotechnology sector. As a Social Media Manager, you will be responsible for analyzing social media data and user behavior to generate actionable insights. You will also track key performance indicators and recommend optimization strategies to enhance our social media presence. It is crucial for the ideal candidate to possess a profound understanding of Social Media Analytics and stay updated on social media trends and algorithm changes.\\n\\nResponsibilities:\\n- Analyze social media data and user behavior to generate actionable insights.\\n- Track key performance indicators and recommend optimization strategies.\\n- Stay updated on social media trends and algorithm changes.\\n- Utilize social media analytics tools such as Google Analytics, Facebook Insights, and other data analysis and reporting tools.\\n- Measure social media ROI and provide reports on performance.\\n- Conduct competitive analysis to identify trends and opportunities.\\n- Collaborate with cross-functional teams to develop and implement social media strategies.\\n- Create engaging and relevant content for social media platforms.\\n- Monitor and respond to social media comments, messages, and inquiries.\\n- Stay up-to-date with industry news and developments in the Pharmaceuticals and Biotechnology sectors.\\n\\nQualifications:\\n- Master of Commerce or equivalent degree in a relevant field.\\n- Demonstrated expertise within the Pharmaceuticals industry, specializing in the Biotechnology sector.\\n- Proficient in social media analytics tools such as Google Analytics, Facebook Insights, etc.\\n- Strong analytical skills with the ability to analyze social media data and user behavior.\\n- Excellent communication and interpersonal skills.\\n- Proven experience in measuring social media ROI and reporting on performance.\\n- Ability to identify trends and opportunities through competitive analysis.\\n- Creative mindset with the ability to create engaging and relevant content.\\n- Strong attention to detail and organizational skills.\\n- Ability to work effectively in a fast-paced and dynamic environment.\\n\\nIf you meet the above qualifications and are passionate about social media and the Pharmaceuticals industry, we would love to hear from you. Apply now to join our team as a Social Media Manager.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f218e9d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:09:26.180224Z",
     "iopub.status.busy": "2024-01-17T21:09:26.179609Z",
     "iopub.status.idle": "2024-01-17T21:09:26.184067Z",
     "shell.execute_reply": "2024-01-17T21:09:26.183183Z"
    },
    "papermill": {
     "duration": 0.016172,
     "end_time": "2024-01-17T21:09:26.186012",
     "exception": false,
     "start_time": "2024-01-17T21:09:26.169840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['Instruction']}\\n ### Answer: {example['Response']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0c5c111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:09:26.204447Z",
     "iopub.status.busy": "2024-01-17T21:09:26.204167Z",
     "iopub.status.idle": "2024-01-17T21:11:19.494148Z",
     "shell.execute_reply": "2024-01-17T21:11:19.493367Z"
    },
    "papermill": {
     "duration": 113.301917,
     "end_time": "2024-01-17T21:11:19.496501",
     "exception": false,
     "start_time": "2024-01-17T21:09:26.194584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b45e6fca9bc45f8bbae42cd6adc6c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5700e679d8141dbbc877734a9322685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b366487b05924fa7b42191a4a15eabea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a665dd01eca41e782abf4fe13818064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3e501b346349fd8933bfc87f78e6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c41338ae16548b2808b5b12ddadf719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b71056d2546496fbaa1bcffb62db84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feefba24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:19.519035Z",
     "iopub.status.busy": "2024-01-17T21:11:19.518696Z",
     "iopub.status.idle": "2024-01-17T21:11:20.423892Z",
     "shell.execute_reply": "2024-01-17T21:11:20.423127Z"
    },
    "papermill": {
     "duration": 0.918603,
     "end_time": "2024-01-17T21:11:20.426007",
     "exception": false,
     "start_time": "2024-01-17T21:11:19.507404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa0e008ac154869b7e898e6b3b720b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bac0602e78241e08c4a61c7b52a11c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7acf8622eb2442896bfb7c0f22e9187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1510f0a8424148f48b045510a2e4a12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ef6e12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:20.448874Z",
     "iopub.status.busy": "2024-01-17T21:11:20.448532Z",
     "iopub.status.idle": "2024-01-17T21:11:27.940367Z",
     "shell.execute_reply": "2024-01-17T21:11:27.939426Z"
    },
    "papermill": {
     "duration": 7.505187,
     "end_time": "2024-01-17T21:11:27.942310",
     "exception": false,
     "start_time": "2024-01-17T21:11:20.437123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac9a78f18924f47947aff01b7f954ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63f7c09b5814e97b8a36fc6e0da7f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df9ec02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:27.965233Z",
     "iopub.status.busy": "2024-01-17T21:11:27.964923Z",
     "iopub.status.idle": "2024-01-17T21:11:27.980109Z",
     "shell.execute_reply": "2024-01-17T21:11:27.979250Z"
    },
    "papermill": {
     "duration": 0.028569,
     "end_time": "2024-01-17T21:11:27.982046",
     "exception": false,
     "start_time": "2024-01-17T21:11:27.953477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generate a job description for a Social Media Manager role.The candidate should have skills in Social media analytics tools example Google Analytics, Facebook Insights Data analysis and reporting Social media ROI measurement Competitive analysis Trend identification. The job description should include the sector (Biotechnology) and industry (Pharmaceuticals) of the company.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset['Instruction'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d85316e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:31.473511Z",
     "iopub.status.busy": "2024-01-17T21:11:31.472670Z",
     "iopub.status.idle": "2024-01-17T21:11:31.477917Z",
     "shell.execute_reply": "2024-01-17T21:11:31.477130Z"
    },
    "papermill": {
     "duration": 0.019287,
     "end_time": "2024-01-17T21:11:31.479848",
     "exception": false,
     "start_time": "2024-01-17T21:11:31.460561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 600 \n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "058ad502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:31.503254Z",
     "iopub.status.busy": "2024-01-17T21:11:31.502966Z",
     "iopub.status.idle": "2024-01-17T21:11:36.913152Z",
     "shell.execute_reply": "2024-01-17T21:11:36.912240Z"
    },
    "papermill": {
     "duration": 5.424309,
     "end_time": "2024-01-17T21:11:36.915405",
     "exception": false,
     "start_time": "2024-01-17T21:11:31.491096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0c40b3facb416da7953b0be54f905c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1312e35e31de40b6a7550224e6de1c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "707d0156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:36.940411Z",
     "iopub.status.busy": "2024-01-17T21:11:36.939717Z",
     "iopub.status.idle": "2024-01-17T21:11:36.969129Z",
     "shell.execute_reply": "2024-01-17T21:11:36.968362Z"
    },
    "papermill": {
     "duration": 0.043728,
     "end_time": "2024-01-17T21:11:36.971038",
     "exception": false,
     "start_time": "2024-01-17T21:11:36.927310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02bcd281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:36.997178Z",
     "iopub.status.busy": "2024-01-17T21:11:36.996891Z",
     "iopub.status.idle": "2024-01-17T21:11:37.002549Z",
     "shell.execute_reply": "2024-01-17T21:11:37.001775Z"
    },
    "papermill": {
     "duration": 0.02054,
     "end_time": "2024-01-17T21:11:37.004430",
     "exception": false,
     "start_time": "2024-01-17T21:11:36.983890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec4399db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:37.028712Z",
     "iopub.status.busy": "2024-01-17T21:11:37.028443Z",
     "iopub.status.idle": "2024-01-17T21:11:37.034840Z",
     "shell.execute_reply": "2024-01-17T21:11:37.034006Z"
    },
    "papermill": {
     "duration": 0.020889,
     "end_time": "2024-01-17T21:11:37.036943",
     "exception": false,
     "start_time": "2024-01-17T21:11:37.016054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2cfebe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:37.061129Z",
     "iopub.status.busy": "2024-01-17T21:11:37.060864Z",
     "iopub.status.idle": "2024-01-17T21:11:37.185652Z",
     "shell.execute_reply": "2024-01-17T21:11:37.184582Z"
    },
    "papermill": {
     "duration": 0.139165,
     "end_time": "2024-01-17T21:11:37.187760",
     "exception": false,
     "start_time": "2024-01-17T21:11:37.048595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3407872 || all params: 3755479040 || trainable%: 0.09074400266124238\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=2,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"v_proj\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.2,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13515523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:37.213364Z",
     "iopub.status.busy": "2024-01-17T21:11:37.212684Z",
     "iopub.status.idle": "2024-01-17T21:11:37.223721Z",
     "shell.execute_reply": "2024-01-17T21:11:37.222764Z"
    },
    "papermill": {
     "duration": 0.02572,
     "end_time": "2024-01-17T21:11:37.225683",
     "exception": false,
     "start_time": "2024-01-17T21:11:37.199963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.2, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.2, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1877dff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:37.294443Z",
     "iopub.status.busy": "2024-01-17T21:11:37.294094Z",
     "iopub.status.idle": "2024-01-17T21:11:37.319138Z",
     "shell.execute_reply": "2024-01-17T21:11:37.318279Z"
    },
    "papermill": {
     "duration": 0.046521,
     "end_time": "2024-01-17T21:11:37.326881",
     "exception": false,
     "start_time": "2024-01-17T21:11:37.280360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74cf80e00ea4a528d26f93e4529d81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "684d0cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:37.353431Z",
     "iopub.status.busy": "2024-01-17T21:11:37.353166Z",
     "iopub.status.idle": "2024-01-17T21:11:37.357278Z",
     "shell.execute_reply": "2024-01-17T21:11:37.356539Z"
    },
    "papermill": {
     "duration": 0.019189,
     "end_time": "2024-01-17T21:11:37.359030",
     "exception": false,
     "start_time": "2024-01-17T21:11:37.339841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: \n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "163c404e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:11:37.384482Z",
     "iopub.status.busy": "2024-01-17T21:11:37.384220Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-01-17T21:11:37.371301",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbevv\u001b[0m (\u001b[33mbev-codes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240117_211137-w9ee6gun\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmistral-jobdesp-finetune-v2-2024-01-17-21-11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/bev-codes/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/bev-codes/huggingface/runs/w9ee6gun\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='559' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [559/562 11:52:27 < 03:50, 0.01 it/s, Epoch 0.99/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.041800</td>\n",
       "      <td>1.011664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"jobdesp-finetune-v2\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=2,\n",
    "        gradient_checkpointing=True,\n",
    "        num_train_epochs = 1,\n",
    "#         max_steps=1350,\n",
    "        learning_rate=1e-5, \n",
    "        fp16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=50,              \n",
    "        logging_dir=\"./logs\",        \n",
    "        save_strategy=\"steps\",       \n",
    "        save_steps=450,                \n",
    "        evaluation_strategy=\"steps\", \n",
    "        eval_steps=450,               \n",
    "        do_eval=True,               \n",
    "        report_to=\"wandb\",           \n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",        \n",
    "        push_to_hub=True,  \n",
    "        hub_model_id=\"BevenRozario/mistral_v3_5k\"\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  \n",
    "trainer.train()\n",
    "trainer.push_to_hub()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-17T21:06:44.874705",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
